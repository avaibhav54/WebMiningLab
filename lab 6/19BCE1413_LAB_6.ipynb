{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c170d3c",
   "metadata": {},
   "source": [
    "## 1\n",
    "Dataset of Restaurant customer reviews.\n",
    "Identify the label -> Positive or Negative of the following query by applying NB classifer with Laplace smoothing\n",
    "\n",
    "test_data 1= Serving good Food absolutely perfect Restaurant\n",
    "\n",
    "Test_data 2= pathetic food ever had"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf58249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d77a6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to  generate  vocabulary for a given training and testing data\n",
    "def get_vocabulary(training_data,testing_data):\n",
    "    vocab = []\n",
    "    for i in training_data:\n",
    "        vocab.extend(i.split(\"-\"))\n",
    "    for i in testing_data:\n",
    "        vocab.extend(i.split(\"-\")) \n",
    "    vocab = list(set(vocab))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eca71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wb = openpyxl.load_workbook(\"data.xlsx\")\n",
    "sheet = wb.active #selecting the sheet\n",
    "\n",
    "training_data = [] #to store the training data\n",
    "training_data_labels = [] #to store the training data classes/labels\n",
    "\n",
    "testing_data = [] #to store the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd956fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch  training data from the excel\n",
    "for i in range(0,9):\n",
    "    c1 = sheet.cell(i+3,2)\n",
    "    c2 = sheet.cell(i+3,3)\n",
    "    training_data.append(str(c1.value))\n",
    "    training_data_labels.append(str(c2.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66436b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the testing data from the excel\n",
    "for i in range(0,2):\n",
    "    c = sheet.cell(i+12,2)\n",
    "    testing_data.append(str(c.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b17268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+----------+\n",
      "|               training data               |  Labels  |\n",
      "+-------------------------------------------+----------+\n",
      "|              Simply-loved-it              | Positive |\n",
      "|    Most-disgusting-Food-I-have-ever-had   | Negative |\n",
      "|       Stay-away-very-disgusting-Food      | Negative |\n",
      "|    menu-is-absolutely-perfect-loved-it    | Positive |\n",
      "|       a-really-good-value-for-money       | Positive |\n",
      "|       this is-a-very-good-Restaurant      | Positive |\n",
      "|            terrible-experience            | Negative |\n",
      "|          this-place-has-best-food         | Positive |\n",
      "| this-place-has-most-pathetic-Serving-food | Negative |\n",
      "+-------------------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "#printing the training data\n",
    "train_tb = PrettyTable([\"training data\",\"Labels\"])\n",
    "for i in range(0,len(training_data)):\n",
    "    train_tb.add_row([training_data[i],training_data_labels[i]])\n",
    "print(train_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb1fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-------+\n",
      "|                   Testing Data                  | Label |\n",
      "+-------------------------------------------------+-------+\n",
      "| Serving-good-Food-absolutely-perfect-Restaurant |   ?   |\n",
      "|              pathetic-food-ever-had             |   ?   |\n",
      "| Serving-good-Food-absolutely-perfect-Restaurant |   ?   |\n",
      "|              pathetic-food-ever-had             |   ?   |\n",
      "+-------------------------------------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "#printing the testing data\n",
    "test_tb = PrettyTable([\"Testing Data\",\"Label\"])\n",
    "for i in range(0,len(testing_data)):\n",
    "    test_tb.add_row([testing_data[i],\"?\"])\n",
    "print(test_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bdd3e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary Size =  35\n",
      "Vocabulary:\n",
      " ['loved', 'had', 'Stay', 'terrible', 'has', 'it', 'Food', 'for', 'Serving', 'money', 'menu', 'this is', 'is', 'disgusting', 'Simply', 'very', 'Restaurant', 'most', 'experience', 'perfect', 'pathetic', 'absolutely', 'value', 'a', 'really', 'good', 'food', 'away', 'I', 'best', 'have', 'Most', 'place', 'this', 'ever']\n"
     ]
    }
   ],
   "source": [
    "#generating the vocabulary from the given training and testing data\n",
    "vocabulary = get_vocabulary(training_data,testing_data)\n",
    "print(\"\\nVocabulary Size = \",len(vocabulary))\n",
    "print(\"Vocabulary:\\n\",vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c50b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prior Class Probabilities:  [0.5555555555555556, 0.4444444444444444]\n"
     ]
    }
   ],
   "source": [
    "#computing the prior class probabilities\n",
    "prior_class_probs = []\n",
    "a = 0\n",
    "b = 0\n",
    "c = 0\n",
    "for i in range(0,len(training_data)):\n",
    "    if training_data_labels[i] == \"Positive\":\n",
    "        a = a + 1\n",
    "    elif training_data_labels[i] == \"Negative\":\n",
    "        b = b + 1\n",
    "prior_class_probs.append(a/len(training_data)) #Positive\n",
    "prior_class_probs.append(b/len(training_data)) #Negative\n",
    "print(\"\\nPrior Class Probabilities: \",prior_class_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5dd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating the dictionary for ever class containing all the words and their frequency\n",
    "Positive_dict = {}\n",
    "Negative_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb203599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Positive' Class Dictionary:\n",
      " {'loved': [2], 'has': [1], 'it': [2], 'for': [1], 'money': [1], 'menu': [1], 'this is': [1], 'is': [1], 'Simply': [1], 'very': [1], 'Restaurant': [1], 'perfect': [1], 'absolutely': [1], 'value': [1], 'a': [2], 'really': [1], 'good': [2], 'food': [1], 'best': [1], 'place': [1], 'this': [1]}\n"
     ]
    }
   ],
   "source": [
    "#generating dictionary for Positive class\n",
    "Positive_all_words = []\n",
    "for i in range(0,len(training_data)):\n",
    "    if training_data_labels[i] == \"Positive\":\n",
    "        Positive_all_words.extend(training_data[i].split(\"-\"))\n",
    "\n",
    "for i in list(set(Positive_all_words)):\n",
    "    Positive_dict[i] = [Positive_all_words.count(i)]\n",
    "\n",
    "print(\"\\n'Positive' Class Dictionary:\\n\",Positive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d849dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Negative' Class Dictionary:\n",
      " {'had': [1], 'Stay': [1], 'terrible': [1], 'has': [1], 'Food': [2], 'Serving': [1], 'disgusting': [2], 'very': [1], 'most': [1], 'experience': [1], 'pathetic': [1], 'food': [1], 'away': [1], 'I': [1], 'have': [1], 'Most': [1], 'place': [1], 'this': [1], 'ever': [1]}\n"
     ]
    }
   ],
   "source": [
    "#generating dictionary for Negative class\n",
    "Negative_all_words = []\n",
    "for i in range(0,len(training_data)):\n",
    "    if training_data_labels[i] == \"Negative\":\n",
    "        Negative_all_words.extend(training_data[i].split(\"-\"))\n",
    "\n",
    "for i in list(set(Negative_all_words)):\n",
    "    Negative_dict[i] = [Negative_all_words.count(i)]\n",
    "\n",
    "print(\"\\n'Negative' Class Dictionary:\\n\",Negative_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbcb7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating conditional probabilities of each word belonging in Positive class\n",
    "for i in list(Positive_dict.keys()):\n",
    "    p = (Positive_dict[i][0] + 1)/(len(Positive_all_words) + len(vocabulary))\n",
    "    Positive_dict[i].append(round(p,4)) #storing the proabality in the dictionary itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6995623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating conditional probabilities of each word belonging in Negative class\n",
    "for i in list(Negative_dict.keys()):\n",
    "    p = (Negative_dict[i][0] + 1)/(len(Negative_all_words) + len(vocabulary))\n",
    "    Negative_dict[i].append(round(p,4)) #storing the proabality in the dictionary itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97b30049",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_labels = [] #to store the test data documents classes/labels\n",
    "#calculating the probablitiy of the choosen test document\n",
    "for i in range(0,len(testing_data)):\n",
    "    #tokenising the document\n",
    "    test_doc_words = []\n",
    "    test_doc_words.extend(testing_data[i].split(\"-\"))\n",
    "    p_Positive = prior_class_probs[0] #assigning the prior probab of class positive\n",
    "    for j in range(0,len(test_doc_words)):\n",
    "        #if word is in the dictionary then directly fetch the probability\n",
    "        if test_doc_words[j] in Positive_dict.keys():\n",
    "            p_Positive = p_Positive * Positive_dict[test_doc_words[j]][1]\n",
    "        #if word is not there in the dictionary compute the probability\n",
    "        else:\n",
    "            #print(\"In else positive class,\"+test_doc_words[j]+\" not there in dict\")\n",
    "            p_Positive = p_Positive * (1/(len(Positive_all_words)+len(vocabulary)))\n",
    "            \n",
    "    #calculating the probab if the doc comes under Negative class\n",
    "    p_Negative = prior_class_probs[1] #assigning the prior probab of class Negative\n",
    "    for j in range(0,len(test_doc_words)):\n",
    "        #if word is in the dictionary then directly fetch the probability\n",
    "        if test_doc_words[j] in Negative_dict.keys():\n",
    "            p_Negative = p_Negative * Negative_dict[test_doc_words[j]][1]\n",
    "        #if word is not there in the dictionary compute the probability\n",
    "        else:\n",
    "            #print(\"In else Negative class,\"+test_doc_words[j]+\" not there in dict\")\n",
    "            p_Negative = p_Negative * (1/(len(Negative_all_words)+len(vocabulary)))\n",
    "\n",
    "\n",
    "    if p_Positive > p_Negative:\n",
    "        #print(\"Assigned to Positive\")\n",
    "        testing_data_labels.append(\"Positive\")\n",
    "    elif p_Positive < p_Negative:\n",
    "        #print(\"Assigned to Negative\")\n",
    "        testing_data_labels.append(\"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe7d40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+----------+\n",
      "|                   Testing Data                  |  Label   |\n",
      "+-------------------------------------------------+----------+\n",
      "| Serving-good-Food-absolutely-perfect-Restaurant | Positive |\n",
      "|              pathetic-food-ever-had             | Negative |\n",
      "| Serving-good-Food-absolutely-perfect-Restaurant | Positive |\n",
      "|              pathetic-food-ever-had             | Negative |\n",
      "+-------------------------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "final_tb = PrettyTable([\"Testing Data\",\"Label\"])\n",
    "for i in range(0,len(testing_data)):\n",
    "    final_tb.add_row([testing_data[i],testing_data_labels[i]])\n",
    "print(final_tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f42190",
   "metadata": {},
   "source": [
    "## 2\n",
    "The dataset . Create your own dataset as data.csv file\n",
    "Identify the class/category è Politics or Business or Sports - of the following query by applying NB classifer with Laplace smoothing\n",
    "\n",
    "(i) query_data = [4,0,2,0,1,0,6,0]\n",
    "\n",
    "(ii) query_data = [0,0,2,0,0 ,9,0,9]\n",
    "\n",
    "(iii) query_data = [5,0,2,5,0 ,9,0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "588ec340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89816d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'lab6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c990d17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   TDP       7 non-null      int64 \n",
      " 1   Nifty     7 non-null      int64 \n",
      " 2   Sidhu     7 non-null      int64 \n",
      " 3   BJP       7 non-null      int64 \n",
      " 4   Sensex    7 non-null      int64 \n",
      " 5   Sixer     7 non-null      int64 \n",
      " 6   Congress  7 non-null      int64 \n",
      " 7   Century   7 non-null      int64 \n",
      " 8   Category  7 non-null      object\n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 632.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69257c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TDP', 'Nifty', 'Sidhu', 'BJP', 'Sensex', 'Sixer', 'Congress',\n",
       "       'Century', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e93ab098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TDP</th>\n",
       "      <th>Nifty</th>\n",
       "      <th>Sidhu</th>\n",
       "      <th>BJP</th>\n",
       "      <th>Sensex</th>\n",
       "      <th>Sixer</th>\n",
       "      <th>Congress</th>\n",
       "      <th>Century</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TDP  Nifty  Sidhu  BJP  Sensex  Sixer  Congress  Century  Category\n",
       "0    4      0      3    5       1      0         6        0  Politics\n",
       "1    0      5      0    2       6      0         1        0  Business\n",
       "2    0      0      6    1       0      4         1        2    Sports\n",
       "3    4      1      0    1       1      0         6        0  Politics\n",
       "4    0      0      0    0       0      5         0        6    Sports\n",
       "5    0      4      0    2       6      0         0        1  Business\n",
       "6    5      0      0    3       0      0         5        0  Politics"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc49c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data= [[4,0,2,0,1,0,6,0],[0,0,2,0,0,9,0,9],[5,0,2,5,0,9,0,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea0474c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputlabels = data['Category'].unique()\n",
    "words = list(data.columns)[:-1]\n",
    "numtraindocuments = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c96601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Politics' 'Business' 'Sports']\n",
      "['TDP', 'Nifty', 'Sidhu', 'BJP', 'Sensex', 'Sixer', 'Congress', 'Century']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(outputlabels)\n",
    "print(words)\n",
    "print(numtraindocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f6d04e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_probability = {}\n",
    "probability = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86ee61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outputClass in outputlabels:\n",
    "    temp_dataframe = data.loc[data['Category']==outputClass]\n",
    "    probability[outputClass]=(temp_dataframe.shape[0]/numtraindocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "715584f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Politics': 0.42857142857142855, 'Business': 0.2857142857142857, 'Sports': 0.2857142857142857}\n"
     ]
    }
   ],
   "source": [
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61a6f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f440910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outputClass in outputlabels:\n",
    "    temp_dataframe = data.loc[data['Category']==outputClass]\n",
    "    total_word_count_in_category =0\n",
    "    for i in range(temp_dataframe.shape[0]):\n",
    "        for word in words:\n",
    "            total_word_count_in_category += temp_dataframe.iloc[i][word]\n",
    "    for word in words:\n",
    "        current_word_count_in_category =0\n",
    "        for i in range(temp_dataframe.shape[0]):\n",
    "            current_word_count_in_category += temp_dataframe.iloc[i][word]\n",
    "            cur_prob = (current_word_count_in_category + ALPHA) / (total_word_count_in_category)\n",
    "            conditional_probability[(word, outputClass)] = cur_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b395c616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional probability after applying smoothing\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('TDP', 'Politics'): 0.3111111111111111,\n",
       " ('Nifty', 'Politics'): 0.044444444444444446,\n",
       " ('Sidhu', 'Politics'): 0.08888888888888889,\n",
       " ('BJP', 'Politics'): 0.2222222222222222,\n",
       " ('Sensex', 'Politics'): 0.06666666666666667,\n",
       " ('Sixer', 'Politics'): 0.022222222222222223,\n",
       " ('Congress', 'Politics'): 0.4,\n",
       " ('Century', 'Politics'): 0.022222222222222223,\n",
       " ('TDP', 'Business'): 0.037037037037037035,\n",
       " ('Nifty', 'Business'): 0.37037037037037035,\n",
       " ('Sidhu', 'Business'): 0.037037037037037035,\n",
       " ('BJP', 'Business'): 0.18518518518518517,\n",
       " ('Sensex', 'Business'): 0.48148148148148145,\n",
       " ('Sixer', 'Business'): 0.037037037037037035,\n",
       " ('Congress', 'Business'): 0.07407407407407407,\n",
       " ('Century', 'Business'): 0.07407407407407407,\n",
       " ('TDP', 'Sports'): 0.04,\n",
       " ('Nifty', 'Sports'): 0.04,\n",
       " ('Sidhu', 'Sports'): 0.28,\n",
       " ('BJP', 'Sports'): 0.08,\n",
       " ('Sensex', 'Sports'): 0.04,\n",
       " ('Sixer', 'Sports'): 0.4,\n",
       " ('Congress', 'Sports'): 0.08,\n",
       " ('Century', 'Sports'): 0.36}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Conditional probability after applying smoothing\\n\")\n",
    "conditional_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "546ed6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {}\n",
    "list_query_dict = []\n",
    "for data in query_data:\n",
    "    for i, word in enumerate(words) :\n",
    "        query_dict[word] = data[i]\n",
    "    list_query_dict.append(query_dict)\n",
    "    query_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bd2539f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'TDP': 4,\n",
       "  'Nifty': 0,\n",
       "  'Sidhu': 2,\n",
       "  'BJP': 0,\n",
       "  'Sensex': 1,\n",
       "  'Sixer': 0,\n",
       "  'Congress': 6,\n",
       "  'Century': 0},\n",
       " {'TDP': 0,\n",
       "  'Nifty': 0,\n",
       "  'Sidhu': 2,\n",
       "  'BJP': 0,\n",
       "  'Sensex': 0,\n",
       "  'Sixer': 9,\n",
       "  'Congress': 0,\n",
       "  'Century': 9},\n",
       " {'TDP': 5,\n",
       "  'Nifty': 0,\n",
       "  'Sidhu': 2,\n",
       "  'BJP': 5,\n",
       "  'Sensex': 0,\n",
       "  'Sixer': 9,\n",
       "  'Congress': 0,\n",
       "  'Century': 9}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_query_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf5c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_result_probability = {}\n",
    "result_probability =[]\n",
    "for query_dict in list_query_dict:\n",
    "    for output_class in outputlabels :\n",
    "        cur_prob = 1\n",
    "        for word in words :\n",
    "            cur_prob *= (conditional_probability[(word, output_class)] ** query_dict[word])\n",
    "            categorical_result_probability[output_class] = cur_prob                  \n",
    "    result_probability.append(categorical_result_probability)\n",
    "    categorical_result_probability = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25e5ab77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Politics': 2.0212765225616147e-08,\n",
       "  'Business': 2.0530257296565003e-16,\n",
       "  'Sports': 2.1045339750400004e-15},\n",
       " {'Politics': 1.3799701971155752e-32,\n",
       "  'Business': 1.2077990336473961e-26,\n",
       "  'Sports': 2.0872693292214035e-09},\n",
       " {'Politics': 2.1796398918917e-38,\n",
       "  'Business': 1.8331882202741092e-37,\n",
       "  'Sports': 7.003713677304523e-22}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b795dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query 1 entered belongs to the category : Politics\n",
      "The query 2 entered belongs to the category : Sports\n",
      "The query 3 entered belongs to the category : Sports\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for categorical_result_probability in result_probability:\n",
    "    result_category = max(categorical_result_probability, key=categorical_result_probability.get)\n",
    "    result_score = categorical_result_probability[result_category]\n",
    "    print(f\"The query {i} entered belongs to the category : {result_category}\")\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
